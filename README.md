# Keras BiLSTM Model for LLM-Generated Text Detection

This project proposes a Deep Learning binary classifier, utilizing a Recurrent Neural Network (RNN) with a Bidirectional Long Short-Term Memory (LSTM) architecture, 
to distinguish between texts written by humans and texts generated by Large Language Models (LLMs). This project was developed as part of the public competition 
***LLM - DETECT AI GENERATED TEXT***, sponsored by **The Learning Agency Lab** on Kaggle 
([competition link](https://www.kaggle.com/competitions/llm-detect-ai-generated-text)).

---

## ‚öôÔ∏è Environments and Tools
- Google Colaboratory and Kaggle platforms;
- Python and IPYNB;
- Keras library and TensorFlow backend;
- Pandas library and Scikit-learn library;
- NLTK (Natural Language Tool-Kit) library;
- Matplotlib library;
- Keras Tuner library (hyper-parameters optimization);

---

## üìä Datasets and Pre-processing
The notebook *`DataAugmentation&Preprocessing.ipynb`* is dedicated to training set creation, data augmentation, and text pre-processing. <br>
The notebook begins by loading the two primary datasets provided by the Kaggle competition: <br>
- **`train_essays.csv`:** contains 1378 text samples. Each sample includes an `id`, `prompt_id`, the `text` content, and a `generated` label
  (0 for human-written, 1 for AI-generated);
- **`train_prompts.csv`:** details the two prompts used to generate the texts. The two prompts are *Car-free cities* (`prompt_id 0`) and *Does the electoral college work?*
  (`prompt_id 1`); <br>

The initial Kaggle competition dataset was limited and imbalanced. Two data augmentation strategies have been adopted by adding **DAIGT (Detection of AI-Generated Texts)** 
datasets from Kaggle: `train_v3_drcat_01.csv`, `train_v3_drcat_02.csv`, `train_v4_drcat_01.csv`, and `daigt_magic_generations.csv`. <br> 
- **Strategy 1:** addition of texts from all DAIGT datasets, filtering only those generated with the two original Kaggle dataset prompts (20,769 total samples);
- **Strategy 2:** addition of texts from the `train_v4_drcat_01.csv` dataset without prompt filtering (73,573 samples with 15 different prompts). `train_prompts.csv` is
  modified to include new prompts;
  
Human-written samples are provided by the competition and by the open-source **Persuade Corpus**. AI-generated texts are obtained from generative models: **LLaMA (Large
Language Model Meta AI)**, **Falcon**, **Mistral 7B**, **OpenAI GTP-3 (DaVinci, Babbage, Curie, Ada)**, **OpenAI GTP-4 (Nima)**, other models **(Intel Neural Chat, Claude,
Moth)**. <br>
Augmented datasets are saved in `.csv` format:
- **`training_set.csv`:** dataset built with only the 2 original Kaggle prompts (augmentation strategy 1);
- **`training_set2.csv`:** dataset built with 15 different prompts (augmentation strategy 2); <br>

<br>

**Text Pre-processing Operations** <br>
- **Normalization:** converting numbers to characters, expanding contractions, removing punctuation and extra spaces, removing non-standard alphabetical characters, and
  converting to lowercase;
- **Tokenization:** breaking down texts into elementary units (words);
- **Toxicity Removal:** filtering out inappropriate language from a list file **`LDNOOBW.txt`** obtained from [GitHub](https://github.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words); 
- **Short Text Filtering:** removing text samples with fewer than 100 words;
- **Stop Words Removal:** eliminating common words without significant meaning;
- **Stemming /Lemmatization:** reducing words to their root/base form; <br>

Six different pre-processing strategies have been defined: <br>
- **Standard:** baseline pre-processing (normalization, tokenization, toxicity removal, short-text filtering);
- **SW:** baseline pre-processing + Stop Words Removal;
- **S:** baseline pre-processing + Stemming;
- **L:** baseline pre-processing + Lemmatization;
- **SWS:** baseline pre-processing + Stop Words Removal + Stemming;
- **SWL:** baseline pre-processing + Stop Words Removal + Lemmatization;

The six different pre-processing strategies have been applied to both augmented datasets, resulting in 12 different datasets, which are all saved in `.csv` format. <br>

We assembled a test set with different text samples from the ones used for training and validation from the following DAIGT datasets: `train_drcat_01.csv`, 
`train_drcat_02.csv`, `train_drcat_03.csv`, and `train_drcat_04.csv`. The assembled test set is saved as **`test_set.csv`**. <br>
The six different pre-processing strategies are also applied to the test, resulting in 6 different test sets, which are also saved in `.csv` format.

---

## üß† Model Architecture
The *`LSTM_NetworkDAIGT.ipynb`* notebook is dedicated to dataset splitting, text vectorization, embedding, DNN architecture definition, training, validation, and testing.<br> 
Pe-processed text samples are divided into training, validation, and testing sets. For smaller datasets (augmentation strategy 1), we have dealt with the lower number of samples by reserving 80% of the datasets for training with K-fold validation, and the remaining 20% of samples for tests. For larger datasets (augmentation strategy 2), a 70% training, 15% validation, and 15% testing split is used. <br>
The model adopts a sequential architecture and includes the following layers:
- **Text Vectorization Layer (Encoder):** implemented using `tf.keras.layers.TextVectorization`, it converts raw token sequences into a numerical format, creating a vocabulary of integer indexes for the most frequent words. It‚Äôs configured with `VOCAB_SIZE=10,000` (number of unique words) and `output_sequence_length=SAMPLE_LENGTH` (a predefined length to which all input sequences are padded or truncated);
- **Embedding Layer (Word Embedding):** implemented using `tf.keras.layers.Embedding`, it associates each vocabulary index with a vector of floating-point vectors, learning dense representations of words which should capture semantic relationships between words. The dimensionality of these word vectors is set by `EMBEDDING_DIM=3000`;
- **Bidirectional LSTM Layers (at least one):** the core of the model consists of one or more `tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(...))` layers. Bidirectional LSTMs process the input text sequence in both forward and backward directions, allowing the model to capture dependencies and context from both past and future words in a sequence. Dropout is applied to these layers to mitigate overfitting;
- **Dense Layers (at least one):** the model is terminated by one or more `tf.keras.layers.Dense` (fully-connected) layers. The final Dense layer uses a sigmoid activation function, outputting a value between 0 and 1, which represents the probability that the input text is AI-generated (label 1) or human-written (label 0). If present, non-terminal dense layer applies ReLU activation function and L2 regularization; <br>

The defined model is trained and validated with `BATCH_SIZE=64`. Two strategies can be followed:
1. Working with smaller datasets (data augmentation strategy 1), the model is subjected to K-fold validation (with K=4), being trained 3 epochs for each fold;
2. Working with larger datasets (data augmentation strategy 2), the model is trained for 5 epochs and then validated on the previously held-out validation set; <br>

For both strategies, loss function and accuracy are displayed as training and validation metrics. <br> 
Finally, the model is tested on both the held-out test set and the test sets assembled in the *`DataAugmentation&Preprocessing.ipynb`* notebook. The following testing metrics are shown: **Loss**, **Accuracy**, **Precision**, **Recall**, **F1-Score**, **Confusion Matrix**, **ROC (Receiver Operating Characteristic) Curve**, **AUC (Area Under ROC Curve)**.

---

## üîß Hyperparameters Optimization and Tuning
The *`LSTM_NetworkDAIGT_Tuning.ipynb`* performs model optimization via hyperparameter tuning using the Keras Tuner library. Many operations performed in the notebook *`LSTM_NetworkDAIGT.ipynb`* are replicated (dataset loading and splitting, text vectorization and embedding, model architecture definition). <br>
The search for optimal hyperparameter configurations is automated by the `Hyperband` function of Keras Tuner, which adopts a **GridSearch** algorithm to find the best combinations (i.e. those maximizing validation accuracy). Key hyperparameters are optimized individually in sequential order:
- Embedding dimensionality (300, 1200, 2400, 3000, 4200);
- Number of additional bidirectional LSTM layers (0 to 2);
- Number of additional dense layers (0 to 2);
- Dimensionality of LSTM units (8, 16, 32, 64);
- Dropout rate for LSTM layers (0.25 or 0.5) and the addition of a traditional dropout layer; <br>

The Keras_Tuner library automatically saves a summary of the tuning process for each hyperparameter:
- **Summary:** information about each trial, including the hyperparameter value, number of training epochs (we have selected 2 training epochs for tuning), and trial accuracy score are saved in `.txt` format;
- **Best Value:** the best hyperparameters configuration is saved in `.json` format;
- **Best model:** the tuner saves the weights of the best-performing models encountered during the search, retrieved using `tuner.get_best_models()`;

---

## üìà Results and Performance
The tuned model was trained, validated, and tested on 12 different versions of the training sets, resulting from the combination of 2 data augmentation strategies and 6 different pre-processing strategies. Both traning/validation history and testing results for each attempt have been saved into `.csv` format. <br>
Notebook *`Results Summary.ipynb`* compares histories and test results of all attempts. <br>
The approach with a larger dataset (data augmentation strategy 2) and hold-out validation showed more stable behavior during training and validation, despite slightly lower absolute scores compared to the approach with a smaller dataset (data augmentation strategy 1) and K-fold validation, which suffered from overfitting. <br>
Specifically, the **SWL** pre-processing combination (baseline + stop words removal + lemmatization) achieved the best overall results in terms of accuracy and generalization capability.

--- 

## üìÇ Repository Content

---

## üéì Credits 
This project has been realized as assignment for the course of Deep Learning, A.A. 2023-2024

Co-authored by: <br> 
- Antonella Fortuna <antonellafortuna32@gmail.com>
- Michele Barbieri <michele.barbieri99@gmail.com>

Master Degree in ARTIFICIAL INTELLIGENCE AND COMPUTER SCIENCE

DEMACS (Dipartimento di Matematica e Informatica)

UNICAL (Universit√† della Calabria)
